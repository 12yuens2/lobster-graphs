\section{Software Engineering Process}
Many different tools and technologies were used in this project to help facilitate the research. The use of these tools and libraries allowed the project to be focused on its methodology without the need or difficulty to implement known algorithms and methods. 
\subsection{Existing software}

\subsubsection{Graph visualisation}
In order to visualise what a graph representation of a lobster may look like, graph drawing software that could import and export into a graph data format was needed. Initially the popular Graphviz and its \texttt{.dot} graph format \cite{graphviz-dot} was explored. The \texttt{dot} graph format had all the attributes needed such as size of nodes and weights of edges, however there was no readily available GUI tool for drawing graphs as Graphviz mostly works on rendering existing \texttt{.dot} files. This was not ideal as the initial stage of the project involved manual annotation of the dataset with graph drawing software, to be done before any automatic generation graph files. 
\n
The open source Gephi \cite{gephi} tool was the next piece of software explored and it was exactly what was needed in terms of a graph drawing tool. It allowed a simple graph to be drawn with nodes and edges labelled, so this could be done on top of a lobster image from the dataset. Further, the software was able to import and export from and into various different file formats such as \texttt{.graphml}, \texttt{.gml}, \texttt{.gdf} and \texttt{.dl}. Unfortunately it did not handle the \texttt{.dot} file format, so a choice had to be made between choosing the drawing tool or more powerful file format. 
\begin{lstlisting}[caption={Header formats for \texttt{.gdf} files showing the kind of node and edge data it could keep.}]
nodedef> name VARCHAR,label VARCHAR,width DOUBLE,height DOUBLE,x DOUBLE,y DOUBLE,color VARCHAR

edgedef> node1,node2,weight DOUBLE,directed BOOLEAN,color VARCHAR
\end{lstlisting}
From exploring the various file formats that Gephi could use, it was discovered that the \texttt{.gdf} format contained enough information for our purposes. Specifically it contained a label, width, height, x and y coordinates for nodes and weights for edges. As such the Gephi tool was used over the Graphviz library and graph format due to its ease of use for drawing and file formats that contained enough information for its intended purpose.

\subsubsection{Graph matching}
Different graph matching and graph querying software was explored to deal with subgraph matching without the need for our own implementation. What was needed was a tool that could find if a labelled subgraph was part of a larger graph in a database of pre-defined lobster graphs. The tool also had to be fast and able to query a large number ($> 100,000$) of subgraphs with sufficient speed. Two tools, GraphGrep \cite{graphgrep} and APPAGATO \cite{appagato} were looked at for this purpose. 
\n
Both tools were similar, using the same input/output formats for graphs and matches. They allowed input graphs nodes to be labelled with names, which was convenient for labelling the different parts of a lobster. The advantage APPAGATO offered over GraphGrep was its parallel GPU implementation for large speed up. During the initial prototyping stage, both tools were tested for their speed and suitability to the problem. Example graphs and queries were created and ran with large numbers of queries to test the speed and scalability of the tools. There was little difference in speed between the two tools for the scale of subgraphs needed in this project as both performed very reasonably for up to 500,000 subgraphs. The one issue found with APPAGATO was that it did not support matching multiple target and query graphs easily as its file format only support one graph per file. GraphGrep on the other hand allowed multiple graphs to be defined in a single file for both its database and queries. For this reason, GraphGrep was used in the subgraph matching stage of the project.

\subsection{Technologies used}

\subsubsection{OpenCV}
OpenCV (Open Source Computer Vision Library) \cite{opencv} is an open source library which contains a vast number of functions and interfaces for computer vision algorithms. The library was used heavily to prevent the need for implementing classical computer vision algorithms such as SIFT \cite{sift} and to make use of its image processing functions such as drawing detected keypoints and calculating colour histograms. This allowed much of the project to focus on the application of these algorithms and the combination of these computer vision techniques with probabilistic graph matching models, rather than need to produce new or classic keypoint detection algorithms. Further, the use of OpenCV exposed many practical underlying concepts and approaches in computer vision which were explored and used.
\n
As OpenCV supports C++, Python, Java and MATLAB, the choice of language used was between these languages. 

\subsubsection{Python}
Python was chosen as the primary language used for development. It is popular in the scientific community thanks to its extensive library support and ease of writing. Since performance was not a major issue, using Python would make it easier and faster to test and prototype different methods without the need for heavy error checking and debugging. Using Python also gives access to powerful libraries such as NumPy and SciPy, providing useful functionality such as probability distributions and matrix manipulation out of the box. Additionally, before the use of OpenCV in the project, the prototyping for probabilistic models, subgraph creation and subgraph matching was already written in Python, making it natural to extend from the prototype after the introduction of OpenCV functions. 
\n
Although Python is a dynamically typed language, newer versions (Python 3.5 and above) have added support for type hints and static type checking with \texttt{mypy} \cite{mypy}. As the implementation of the project grew, the addition of type hints was added to keep the code organised and readable. This was especially helpful to express the types of data contained in lists and tuples. 