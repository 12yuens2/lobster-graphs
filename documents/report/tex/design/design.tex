\section{Design}
\newcommand{\imgpath}{tex/design/imgs}
\vspace{1cm}
\subsection{Annotation of dataset}
The dataset provided by \cite{lobster-thesis} was tagged with information on each image such as the lobster's sex, length of 

\imagefig{1\textwidth}{\imgpath/annotated.JPG}{Example of annotated lobster image with nodes and edges of the graph perfectly matched.}

\subsection{Keypoint detection}
First, to identify important parts from our lobster images, keypoints or areas of interest must be identified. \texttt{OpenCV} \cite{opencv} provides a host of different algorithms for feature detection such as Harris and Shi-Tomasi corner detectors and SIFT, SURF, ORB to extract keypoints \cite{opencv-tut1}. All these algorithms were tried and tested on a small subset of the dataset to see if any would provide both useful and consistent features that can be used. 

\begin{figure}[H]
%\centering
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-harris.png}
	\caption{Harris corner detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-shi-tomasi.png}
	\caption{Shi-Tomasi corner detection}
	\end{subfigure}
	
	\vspace{0.5cm}
	
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-sift.png}
	\caption{SIFT keypoint detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-surf.png}
	\caption{SURF keypoint detection}
	\end{subfigure}
	
\caption{Comparison of different feature detection algorithms. The images have been scaled down after applying the detection to more clearly show the keypoints. Further comparison of the different detection algorithms on more images can be found in appendix \ref{apdx:cv-algos}}
\end{figure}
\begin{figure}[H]
%\centering
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-harris2.png}
	\caption{Harris corner detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-shi-tomasi2.png}
	\caption{Shi-Tomasi corner detection}
	\end{subfigure}
	
	\vspace{0.5cm}
	
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-sift2.png}
	\caption{SIFT keypoint detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-surf2.png}
	\caption{SURF keypoint detection}
	\end{subfigure}
	
\caption{Comparison of different feature detection algorithms on an image with more noise.}
\end{figure}
\noindent
From visually seeing the effects of each algorithm, it can be seen that the corner detectors do not work very well for our purpose. The shape of the lobster is not fully detected reliably. For images with a noisier background, much of the background such as slabs with sharp contrasting corners are also detected. Furthermore, although corner detectors have applications in image matching \cite{corner-detection}, our goal from feature detection is to be able to extract graph like objects or features to apply graph matching on and so corner detection seems unsuitable. 

The keypoint detectors are able to provide better results for our objective, as we can see keypoints of important body parts being identified, such as the body, tail and claws. These keypoints are further able to be consistently identified from multiple images, showing that use of these algorithms are promising for automatically detecting the various parts of the lobster for construction of a graph. There is still a lot of noise in the detected keypoints, but different methods can be applied to filter out unwanted keypoints. It is also non-trivial to create a graph from an outline of corners to represent the shape of a lobster, whereas the keypoints naturally translate well as nodes of a graph, with edges connecting them to form the shape and pose of a lobster. Because of these reasons, the keypoint detection algorithms in SIFT, SURF and ORB were further investigated while the corner detectors were discarded.

\begin{figure}[H]
\centering
TODO  fig of keypoint detector algorithm comparison
\caption{Comparison of different keypoint detection algorithms on multiple lobster images. See comparison of more images in appendix \ref{apdx:cv-algos}}
\end{figure}
\noindent

Between the different keypoint detection algorithms, SIFT was chosen as it gave the most consistent results and the kind of useful keypoints that are needed.


\subsection{Keypoint filtering}
From just running a SIFT detector on the lobster images, it can be seen that there are a lot of small keypoints that are unimportant for our purposes. There are also many keypoints around the lobster that we would like to filter out, as we want all our keypoints to be on the lobster. Initially, the classic vision approach for feature matching using the keypoint descriptors \cite{sift} was tried, but the results obtained were surprisingly poor. Because of this, a more novel approach was taken for filtering. The small keypoints are filtered out by specifying an octave where all keypoints below the octave are filtered. Larger keypoints that are not on the lobster are filtered with a colour histogram method where the histograms of the keypoints are compared and any below a certain threshold are filtered.

\subsubsection{SIFT descriptors}
In computer vision, keypoint descriptors obtained from detectors like SIFT and SURF are often used for feature matching \cite{cv-matching}. Lowe's paper \cite{sift} on the SIFT detector states that keypoints descriptors are highly distinctive, allowing a single feature to be correctly matching with good probability in a large database of features. This is exactly what we want, as we wish to extract the different features of a lobster (tail, claws, head). The only difference is we do not have a dataset of the lobsters, but not of dataset of individual lobster parts. 
\n
Because we do not have a dataset for individual parts, it made more sense to do the opposite of matching. Instead of using the distance between descriptors to match a detected keypoint with a known keypoint, the distance can be used as filter out keypoints that do not match closely to known ones. This distance can then be used as a threshold to filter more or less keypoints away. 
\n
As a test, the descriptor for the important body keypoint was taken from one image and calculated. The descriptor was then matched to the closest other keypoints on another image to see if the body could be identified again. 

\begin{figure}[H]
\centering
TODO keypoint descriptor matching other image
\caption{The image on the left shows the keypoint that the descriptor was calculated from and the image on the right is the closest TODO matched keypoints to that descriptor.}
\label{fig:kp-descriptor}
\end{figure}
\noindent
Figure \ref{fig:kp-descriptor} shows that the use of keypoint descriptors as a means of matching or filtering was not very reliable. TODO
\n
As the traditional method of descriptors proved unreliable for our means, a slightly more novel method was needed to filter out keypoints. (TODO sentance wording)

\subsubsection{Octave filtering}
SIFT uses a Difference of Gaussians for different octaves of the image.  TODO. The octaves represent. It was noticed from the keypoint information provided 


\subsubsection{Colour histogram filtering}


\subsection{Graph creation}

\subsubsection{Probabilistic model}

\subsection{Graph matching}

\subsubsection{Subgraph matching}

\subsubsection{Subgraph rebuilding}
