\section{Methodology}\label{sec:design}
\renewcommand{\imgpath}{tex/design/imgs}
\vspace{1cm}

\subsection{Overview}
Figure \ref{fig:overview} shows the key steps of overall method used to go from an image of a lobster to a labelled graph of the lobster. In the initial stages, keypoints are extracted and filtered from the image through the use of various OpenCV algorithms and techniques such as SIFT for keypoint detection and colour histograms for keypoint filtering. The remaining set of keypoints are then labelled using Bayes' theorem and all permutations of possible subgraphs are created. Next, the subgraphs are matched using GraphGrep \cite{graphgrep} and all matches combined using probability models to get the final lobster graph. 
\begin{figure}[H]
\centering
\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}
\node (raw) [data] {Lobster image};
\node (extraction) [process, right of=raw, xshift=2cm] {Keypoint extraction};
\node (creation) [process, right of=extraction, xshift=2cm] {Subgraph creation};
\node (subgraph) [data, right of=creation, xshift=2cm] {Lobster subgraphs};

\draw [arrow] (raw) -- (extraction);
\draw [arrow] (extraction) -- (creation);
\draw [arrow] (creation) -- (subgraph);

\end{tikzpicture}
\caption{Initial process of creating labelled subgraphs for matching.}
\vspace{0.7cm}
\end{subfigure}

\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}
\node (subgraph) [data] {Lobster subgraphs};
\node (graphgrep) [process, right of=subgraph, xshift=2cm] {Subgraph matching};
\node (model) [process, right of=graphgrep, xshift=2cm] {Build complete graph (TODO name)};
\node (graph) [data, right of=model, xshift=2cm] {Matched lobster graph};

\draw [arrow] (subgraph) -- (graphgrep);
\draw [arrow] (graphgrep) -- (model);
\draw [arrow] (model) -- (graph);
\end{tikzpicture}
\caption{Process of taking the labelled subgraphs to creating a full lobster graph.}
\end{subfigure}
\caption{Flow chart of the whole matching process from getting keypoints to creation of the lobster graphs.}
\label{fig:overview}
\end{figure}
\noindent
A subset of the dataset was taken to create a database of manually annotated attributed lobster graphs. This dataset is important for many aspects of the overall method as it is the set of complete graphs for subgraph matching. Further, the attributes such as node labels, node sizes and edge weights contribute as a basis for the probability models used in both subgraph creation and rebuilding a complete lobster graph. 
\subsection{Annotation of dataset}
The dataset provided by \cite{lobster-thesis} was tagged with information on each image such as the lobster's sex, length of the carapace and width of the tail. To be able to apply the probability models to the dataset and match to complete lobster graphs, the dataset had to be further annotated as attributed graphs. This was initially done and prototyped using Gephi to explore different graph configurations. Later, with the introduction of applying OpenCV keypoint detection algorithms, the annotations were amended with the detected keypoints to include node sizes and edge lengths.

\begin{figure}
\centering
TODO Gephi prototype lobster graph
\end{figure}
\noindent
In the first lobster graph prototyping done with Gephi, 

\imagefig{1\textwidth}{\imgpath/annotated.JPG}{Example of annotated lobster image with nodes and edges of the graph perfectly matched.}

\subsection{Keypoint detection}
First, to identify important parts from our lobster images, keypoints or areas of interest must be identified. OpenCV \cite{opencv} provides a host of different algorithms for feature detection such as Harris and Shi-Tomasi corner detectors and SIFT, SURF, ORB keypoint detectors \cite{opencv-tut1}. All these algorithms were tried and tested on a small subset of the dataset to see if any would provide both useful and consistent features that can be used. 

\begin{figure}[H]
%\centering
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, scale=0.2, keepaspectratio]{\imgpath/img-harris.png}
	\caption{Harris corner detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, scale=0.2, keepaspectratio]{\imgpath/img-shi-tomasi.png}
	\caption{Shi-Tomasi corner detection}
	\end{subfigure}
	
	\vspace{0.5cm}
	
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-sift.png}
	\caption{SIFT keypoint detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-surf.png}
	\caption{SURF keypoint detection}
	\end{subfigure}
	
\caption{Comparison of different feature detection algorithms. The images have been scaled down after applying the detection to more clearly show the keypoints. Further comparison of the different detection algorithms on more images can be found in appendix \ref{apdx:cv-algos}}
\end{figure}
\begin{figure}[H]
%\centering
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, scale=0.2, keepaspectratio]{\imgpath/img-harris2.png}
	\caption{Harris corner detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, scale=0.2, keepaspectratio]{\imgpath/img-shi-tomasi2.png}
	\caption{Shi-Tomasi corner detection}
	\end{subfigure}
	
	\vspace{0.5cm}
	
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-sift2.png}
	\caption{SIFT keypoint detection}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/img-surf2.png}
	\caption{SURF keypoint detection}
	\end{subfigure}
	
\caption{Comparison of different feature detection algorithms on an image with more noise.}
\label{fig:kp-comparison-noise}
\end{figure}
\noindent
From visually seeing the effects of each algorithm, it can be seen that the corner detectors do not work very well for our purpose. The shape of the lobster is not fully detected reliably. For images with a noisier background, much of the background such as slabs with sharp contrasting corners are also detected, as shown in figure \ref{fig:kp-comparison-noise}. Furthermore, although corner detectors have applications in image matching \cite{corner-detection}, our goal from feature detection is to be able to extract graph like objects or features to apply graph matching on and so corner detection is unsuitable as we are not looking to match the different images to each other directly. 

The keypoint detectors are able to provide better results for our objective, as we can see keypoints of important body parts being identified, such as the body, tail and claws. These keypoints are further able to be consistently identified from multiple images, showing that use of these algorithms are promising for automatically detecting the various parts of the lobster for construction of a graph. There is still a lot of noise in the detected keypoints, but we shall see later in section \ref{sec:kp-filter} that different methods can be applied to filter out unwanted keypoints. It is also non-trivial to create a graph from an outline of corners to represent the shape of a lobster, whereas the keypoints naturally translate well as nodes of a graph, with edges connecting them to form the shape and pose of a lobster. Because of these reasons, the keypoint detection algorithms in SIFT, SURF and ORB were further investigated while the corner detectors were discarded.

\begin{figure}[H]
\centering
TODO  fig of keypoint detector algorithm comparison
\caption{Comparison of different keypoint detection algorithms on multiple lobster images. See comparison of more images in appendix \ref{apdx:cv-algos}}
\end{figure}
\noindent

Between the different keypoint detection algorithms, SIFT was chosen as it gave the most consistent results and the kind of useful keypoints that are needed. TODO


\subsection{Keypoint filtering}\label{sec:kp-filter}
From just running a SIFT detector on the lobster images, it can be seen that there are a lot of small keypoints that are unimportant for our purposes. There are also many keypoints around the lobster that we would like to filter out, as we want all our keypoints to be on the lobster. Initially, the classic vision approach for feature matching using the keypoint descriptors \cite{sift} was tried, but the results obtained were surprisingly poor. Because of this, a more novel approach was taken for filtering. The small keypoints are filtered out by specifying an octave where all keypoints coming from that octave or above are kept. Finally, remaining keypoints that are not on the lobster are filtered with a colour histogram method where the colour histograms of the keypoints are compared and any below a certain difference threshold are filtered away.

\subsubsection{SIFT descriptors}
In computer vision, keypoint descriptors obtained from detectors like SIFT and SURF are often used for feature matching \cite{cv-matching}. Lowe's paper \cite{sift} on the SIFT detector states that keypoints descriptors are highly distinctive, allowing a single feature to be correctly matching with good probability in a large database of features. This is exactly what we want, as we wish to extract the different features of a lobster (tail, claws, head). The only difference is we do not have a dataset of the lobsters, but not of dataset of individual lobster parts. 
\n
Because we do not have a dataset for individual parts, it made more sense to do the opposite of matching. Instead of using the distance between descriptors to match a detected keypoint with a known keypoint, the distance can be used as filter out keypoints that do not match closely to known ones. This distance can then be used as a threshold to filter more or less keypoints away. 
\n
As a test, the descriptor for the important body keypoint was taken from one image and calculated. The descriptor was then matched to the closest other keypoints on another image to see if the body could be identified again. 

\begin{figure}[H]
\centering
TODO keypoint descriptor matching other image
\caption{The image on the left shows the keypoint that the descriptor was calculated from and the image on the right is the closest TODO matched keypoints to that descriptor.}
\label{fig:kp-descriptor}
\end{figure}
\noindent
Figure \ref{fig:kp-descriptor} shows that the use of keypoint descriptors as a means of matching or filtering was not very reliable. TODO
\n
As the traditional method of descriptors proved unreliable for our means, a slightly more novel method was needed to filter out keypoints. (TODO sentance wording)

\subsubsection{Octave filtering}
The method of filtering by the actual size of the keypoints was first looked at before looking at octaves. It was found to be less robust and less general than using octave levels. There are a few issues involved in using size of the keypoint for filter, namely how to choose a suitable threshold. The size threshold must be constant across all images, otherwise the method will not be able to generalise to unseen images. The size of the keypoints is directly related to the size of the original image, so any size filter threshold must be calculated based on the size of the image. This is not an issue, as a constant size threshold can be relative to the size of the image. However, with different sizes of lobsters, an aggressive threshold may remove important keypoints that we wanted to keep. Conversely a more conservative threshold would not remove enough keypoints and cause a large combinatorial explosion, a problem explained later in section \ref{sec:probabilistic-model} that we wish to avoid. This makes it difficult to set a good threshold as it would have to be arbitrarily defined and based solely on manual inspection of the images and keypoints sizes of the dataset. Furthermore, this seems to be quite a crude method TODO. 

Octaves in SIFT are created by continually blurring an image. The idea behind this is to emulate looking at the image from different distances to get a varied set of keypoints. This means different features may be found at different octave levels. The high resolution of the images in our dataset causes many small keypoints to be found in the first few octave levels. These keypoints show many details that are irrelevant as we are concerned with the overall pose and size of the lobster.

\begin{figure}[H]
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/sift-raw.png}
	\caption{Before octave filtering}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/sift-octave.png}
	\caption{After octave filtering}
	\end{subfigure}
\caption{Before and after applying a filter on keypoints based on the octave level the keypoints were found in.}
\end{figure}
\noindent
From this observation, we can apply a filter on all keypoints found below a certain octave level so that we are only left with the larger keypoints that capture the features we are looking for. A filter for all keypoints found below octave level 3 was used. This octave level threshold is highly dependent on the size and resolution of the original image. An image with lower size and resolution may need a lower threshold or none at all (TODO reason). 


\subsubsection{Colour histogram filtering}
After applying the octave filter, there still remains some noisy keypoints that need to be removed. Most notably are the keypoints found on the white background of the images. There have been studies \cite{color-histogram} \cite{color-filter} that show applying a colour filter to eliminate unwanted feature points can be quite effective, especially if the background is very different from the target of the image. Following from this, colour histograms of each keypoints were calculated and compared to a set of pre-defined histograms. The difference between the histograms was compared and only keypoints whose different is above a certain threshold are kept. 

\begin{figure}[H]
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/sift-octave.png}
	\caption{Octave filtering}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\linewidth, keepaspectratio]{\imgpath/sift-histogram.png}
	\caption{Octave + colour histogram filtering}
	\end{subfigure}
\caption{Difference between applying only octave filtering and applying both octave and colour histogram filtering.}
\end{figure}
\noindent
The pre-defined histograms TODO
\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth, keepaspectratio]{\imgpath/noisy-keypoints.png}
\caption{Keypoints detected after filtering, showing the weakness of colour histogram filtering against noise.}
\label{fig:noisy-histogram}
\end{figure}
\noindent
A potential issue that was not fully explored is the application of this approach to noisy backgrounds. The colour histograms are effective due to the large contrast between the white background and the lobster. However, this means that keypoints detected in noisy backgrounds that have similar dark colours are not filtered out. Figure \ref{fig:noisy-histogram} shows an image with more in the background and it can be seen that multiple keypoints from the background not belonging to the lobster are kept. (TODO ref return to issue in results)

\subsection{Subgraph creation}
With a set of keypoints extracted and filtered from the image, the next step was to label the keypoints and create permutations of subgraphs to be matched. To reduce problems with combinatorial explosions when creating subgraph permutations, the number of labels assigned to each point and the size of the subgraphs have to be kept low.  
\subsubsection{Node labelling}\label{sec:probabilistic-model}
A simple probabilistic model was used to determine how to label the keypoints through the use of Bayes' Theorem. 
\begin{equation}
P(label | size) = \frac{P(size | label)P(label)}{P(size)}
\end{equation}
The three probabilities $P(size | label)$, $P(label)$, $P(size)$ are defined as follows:
\begin{itemize}
\item $P(size | label)$ - This probability was found using a normal distribution for all sizes of the particular label found in the annotated dataset.
\item $P(label)$ - This is defined as how often that label appears in the annotated dataset relative to the total number of all labels. For example, if there were a total of 100 labels and the \textit{body} label appears 20 times, then $P(label = body) = \frac{20}{100}$.
\item $P(size)$ - The probability of keypoint sizes again uses a normal distribution for all keypoint sizes in the annotated dataset.
\end{itemize}
With the probability calculated for each possible labelling for every keypoint, the labels can be applied based on a threshold. This means multiple labels can be applied to the same keypoint and each separate labelling must be treated as a separate node during subgraph creation. The threshold for labelling represents the trade off between computation required and completeness. If the threshold is too high, then we may miss many potential labels. This is important because the size of the annotated dataset is quite small, so there is a high standard deviation in the distributions for label sizes. On the other hand, if the threshold is too low, then too many labels are applied, leading to a combinatorial explosion when creating the permutations of subgraphs. The result of the labelling process is a list of tuples containing a keypoint and its label. Having all the keypoints labelled, the next step is to create subgraphs where the nodes are represented by labelled keypoints and edges are defined  between the nodes to create the subgraph. 

\subsubsection{Subgraph permutations}
To create labelled subgraphs from the labelled keypoints, all possible permutations are produced. The size of the subgraph to create (and therefore the size of the permutation) is an important consideration in this step. The equation for the number of permutations of size $k$ from $n$ labelled keypoints is as follows:
\begin{equation}
P(n, k) = \frac{n!}{(n-k)!}
\end{equation}
A large $k$ would make the matching step easier as a larger subgraph conveys more information about the node labels and connectivity, so there would be fewer but more distinct matches. However, this would lead to considerably more permutations, for example, given 20 labelled nodes, there would be 6840 possible permutations for $k=3$ while $k=4$ would give 116280 permutations. Having this combinatorial explosion is unsustainable. Though a single permutation cannot contain the same keypoint with two different labels, each permutation of a single keypoint and its multiple labels must be explored. Further these are permutations so the order matters as it directly represents the connection of the nodes to edges.
\begin{figure}[H]
\centering
	\begin{subfigure}{0.45\textwidth}
	\centering
	\begin{tikzpicture}
	\node (body) [circle, draw, minimum size=1.5cm] {body};
	\node (claw) [circle, draw, minimum size=1.5cm, right of=body, xshift=1cm] {claw};
	\node (tail) [circle, draw, minimum size=1.5cm, right of=claw, xshift=1cm] {tail};
	
	\draw (body) -- (claw);
	\draw (claw) -- (tail);
	\end{tikzpicture}
	\caption{Permutation (body, claw, tail)}
	\end{subfigure}
	\hspace*{\fill}
	\begin{subfigure}{0.45\textwidth}
	\centering
	\begin{tikzpicture}
	\node (claw) [circle, draw, minimum size=1.5cm] {claw};
	\node (body) [circle, draw, minimum size=1.5cm, right of=claw, xshift=1cm] {body};
	\node (tail) [circle, draw, minimum size=1.5cm, right of=body, xshift=1cm] {tail};
	
	\draw (claw) -- (body);
	\draw (body) -- (tail);
	\end{tikzpicture}
	\caption{Permutation (claw, body, tail)}
	\end{subfigure}
\caption{The order of the permutations matters as it determines the edges between the nodes.}
\end{figure}
\noindent
A subgraph size of 3 was chosen in the end as it was a strong middle ground between retaining enough information for effective subgraph matching and not causing a large number of permutations to match. A size of 2 is ineffective for matching, it leads to too many successful matches because it is easy to find subgraphs of two nodes and one connecting edge as long as the labels are correct. However using 4 nodes as the subgraph led to too many permutations being produced, leading to a slow process in matching. This is why subgraphs of size 3 were chosen.
\n


\subsection{Graph matching}
The crucial step of taking a large list of subgraphs and matching them to rebuild the complete lobster graph consists of two main steps:
\begin{enumerate}
\item Run GraphGrep to find all subgraphs of valid configurations against the database of complete lobster graphs. 
\item Use the probability of each remaining subgraph to piece together the complete lobster graph.
\end{enumerate}
\subsubsection{Subgraph matching}
After the matching step with GrapGrep, the list of matches is used to pick out the matched permutations. During this step, the lengths of the edges between each node is taken into account. This acts as a late filter step for keypoints that may not be on the lobster, not allowing graph configurations where the points are too far apart to make sense. For example if the distance between an \textit{arm} node and \textit{claw} node is the same as the distance between a \textit{body} and \textit{tail}, the \textit{arm}/\textit{claw} permutation will be discarded. This is helpful in discarding keypoints that are far away from the lobster, for example on the edges of the background. 
\subsubsection{Subgraph rebuilding}
